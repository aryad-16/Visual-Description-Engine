{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pickle import dump\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "def extract_features(directory):\n",
    "\tmodel = VGG16()\n",
    "\tmodel.layers.pop()\n",
    "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "\tprint(model.summary())\n",
    "\tfeatures = dict()\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\timage = load_img(filename, target_size=(224, 224))\n",
    "\t\timage = img_to_array(image)\n",
    "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\t\timage = preprocess_input(image)\n",
    "\t\tfeature = model.predict(image, verbose=0)\n",
    "\t\timage_id = name.split('.')[0]\n",
    "\t\tfeatures[image_id] = feature\n",
    "\t\tprint('>%s' % name)\n",
    "\treturn features\n",
    "\n",
    "directory = 'Flicker30k_Dataset'\n",
    "features = extract_features(directory)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "dump(features, open('features.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fa93f45",
   "metadata": {},
   "source": [
    "Caption Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def load_descriptions(doc):\n",
    "\tmapping = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\ttokens = line.split()\n",
    "\t\tif len(line) < 2:\n",
    "\t\t\tcontinue\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\timage_id = image_id.split('.')[0]\n",
    "\t\timage_desc = ' '.join(image_desc)\n",
    "\t\tif image_id not in mapping:\n",
    "\t\t\tmapping[image_id] = list()\n",
    "\t\tmapping[image_id].append(image_desc)\n",
    "\treturn mapping\n",
    "\n",
    "def clean_descriptions(descriptions):\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor i in range(len(desc_list)):\n",
    "\t\t\tdesc = desc_list[i]\n",
    "\t\t\tdesc = desc.split()\n",
    "\t\t\tdesc = [word.lower() for word in desc]\n",
    "\t\t\tdesc = [w.translate(table) for w in desc]\n",
    "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
    "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
    "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
    "\n",
    "def to_vocabulary(descriptions):\n",
    "\tall_desc = set()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "def save_descriptions(descriptions, filename):\n",
    "\tlines = list()\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor desc in desc_list:\n",
    "\t\t\tlines.append(key + ' ' + desc)\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    "\n",
    "filename = 'Flickr30k.token.txt'\n",
    "doc = load_doc(filename)\n",
    "descriptions = load_descriptions(doc)\n",
    "print('Loaded: %d ' % len(descriptions))\n",
    "clean_descriptions(descriptions)\n",
    "vocabulary = to_vocabulary(descriptions)\n",
    "print('Vocabulary Size: %d' % len(vocabulary))\n",
    "save_descriptions(descriptions, 'descriptions.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14c9b3e0",
   "metadata": {},
   "source": [
    "Loading Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\ttokens = line.split()\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions\n",
    "\n",
    "def load_photo_features(filename, dataset):\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\tfeatures = {k: all_features[k] for k in dataset}\n",
    "\treturn features\n",
    "\n",
    "filename = 'Flickr_30k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "train_features = load_photo_features('features.pkl', train)\n",
    "print('Photos: train=%d' % len(train_features))\n",
    "train_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import tensorflow\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\ttokens = line.split()\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions\n",
    "\n",
    "def load_photo_features(filename, dataset):\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\tfeatures = {k: all_features[k] for k in dataset}\n",
    "\treturn features\n",
    "\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "def max_length(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\treturn max(len(d.split()) for d in lines)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
    "\tX1, X2, y = list(), list(), list()\n",
    "\tfor desc in desc_list:\n",
    "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
    "\t\tfor i in range(1, len(seq)):\n",
    "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
    "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\t\t\tX1.append(photo)\n",
    "\t\t\tX2.append(in_seq)\n",
    "\t\t\ty.append(out_seq)\n",
    "\treturn array(X1), array(X2), array(y)\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "\tinputs1 = Input(shape=(4096,))\n",
    "\tfe1 = Dropout(0.5)(inputs1)\n",
    "\tfe2 = Dense(256, activation='relu')(fe1)\n",
    "\tinputs2 = Input(shape=(max_length,))\n",
    "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "\tse2 = Dropout(0.5)(se1)\n",
    "\tse3 = LSTM(256)(se2)\n",
    "\tdecoder1 = add([fe2, se3])\n",
    "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
    "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\tprint(model.summary())\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(descriptions, photos, tokenizer, max_length):\n",
    "\twhile 1:\n",
    "\t\tfor key, desc_list in descriptions.items():\n",
    "\t\t\tphoto = photos[key][0]\n",
    "\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n",
    "\t\t\tyield [[in_img, in_seq], out_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Flickr_30k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "train_features = load_photo_features('features.pkl', train)\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max_length(train_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08485fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(vocab_size, max_length)\n",
    "epochs = 20\n",
    "steps = len(train_descriptions)\n",
    "for i in range(epochs):\n",
    "\tgenerator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "\tmodel.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "\tmodel.save('model_' + str(i) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
